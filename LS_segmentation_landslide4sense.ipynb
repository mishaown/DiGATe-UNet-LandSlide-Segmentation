{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d56ecf90",
   "metadata": {},
   "source": [
    "### Experiment Details\n",
    "\n",
    "- **Dataset:** LandSlide4Sense  \n",
    "- **Regularized:** Yes\n",
    "- **Model:** DiGATe_Unet\n",
    "- **Backbone:** EfficientNet (tf_efficientnet_b4)\n",
    "- **Data:** 6 Bands, RGB, NDVI, SLOPE, DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed041afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EX_NO = 'L00' # Experiment number. weights, results will save with this extention, works like a unique identification number.\n",
    "# Data directory\n",
    "DATA_DIR = \"ADD YOUR DATA DIRECTORY HERE\" # e.g, /home/user1/ms/Datasets/bijie\n",
    "# Base directory\n",
    "BASE_DIR = \"ADD YOUR BASE DIRECTORY HERE\" # Current directory of the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d40ae",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e0f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dataset import LandSlide4Sense\n",
    "\n",
    "def check_path(path):\n",
    "    if os.path.exists(path):\n",
    "        print(f\"{path} ✅\")\n",
    "    else:\n",
    "        print(f\"{path}❌\")\n",
    "\n",
    "train_path = os.path.join(DATA_DIR, \"TrainData\")\n",
    "check_path(train_path)\n",
    "val_path = os.path.join(DATA_DIR, \"ValidData\")\n",
    "check_path(val_path)\n",
    "test_path = os.path.join(DATA_DIR, \"TestData\")\n",
    "check_path(test_path)\n",
    "\n",
    "train_ds = LandSlide4Sense(data_dir=train_path)\n",
    "val_ds = LandSlide4Sense(data_dir=val_path)\n",
    "test_ds = LandSlide4Sense(data_dir=test_path)\n",
    "\n",
    "print()\n",
    "print(f\"Number of training samples: {len(train_ds)}\")\n",
    "print(f\"Number of validation samples: {len(val_ds)}\")\n",
    "print(f\"Number of test samples: {len(test_ds)}\")\n",
    "print()\n",
    "\n",
    "image, label, filename = train_ds[0]\n",
    "\n",
    "print(f\"Sample name: {filename}\")\n",
    "print(f\"Image shape: {image.shape} (type: {type(image)})\")\n",
    "print(f\"Label shape: {label.shape} (type: {type(label)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee66572",
   "metadata": {},
   "source": [
    "**Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9069463",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show14bands\n",
    "show14bands(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca181931",
   "metadata": {},
   "source": [
    "**Data Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117c3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TwoComposites_l4s\n",
    "from dataset import DualStreamTransform\n",
    "\n",
    "train_dataset = TwoComposites_l4s(train_ds, bands='RGB-NDVI-SLOPE-DEM', resize_to=256, transform=DualStreamTransform())\n",
    "val_dataset = TwoComposites_l4s(val_ds, bands='RGB-NDVI-SLOPE-DEM', resize_to=256, transform=None)\n",
    "test_dataset = TwoComposites_l4s(test_ds, bands='RGB-NDVI-SLOPE-DEM', resize_to=256, transform=None)\n",
    "\n",
    "# Checking on smaple\n",
    "image1, image2, mask = train_dataset[0]\n",
    "\n",
    "print(type(image1), image1.shape, image1.min().item(), image1.max().item())\n",
    "print(type(image2), image2.shape, image2.min().item(), image2.max().item())\n",
    "print(type(mask), mask.shape, mask.min().item(), mask.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d8edf0",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17abf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from models import  DiGATe_Unet_V6\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {DEVICE}')\n",
    "\n",
    "model =  DiGATe_Unet_V6(\n",
    "        n_classes=1,\n",
    "        backbone=\"resnet101\",\n",
    "        n_channels=3,\n",
    "        pretrained=True,          \n",
    "        pretrained_path=None,      \n",
    "        use_input_adapter=False,\n",
    "        freeze_backbone=True,\n",
    "        share_backbone=False\n",
    "    ).to(DEVICE)\n",
    "\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "print(f\"Trainable parameters: {trainable_params:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3653e940",
   "metadata": {},
   "source": [
    "**Hyperparams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abccd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters  \n",
    "BATCH_SIZE = 32           \n",
    "NUM_EPOCHS = 60          \n",
    "LEARNING_RATE = 3e-4     \n",
    "WEIGHT_DECAY = 1e-4        \n",
    "PIN_MEMORY = True           \n",
    "PATIENCE_LIMIT = 20   \n",
    "NUM_CLASSES = 1\n",
    "\n",
    "SAVE_PATH = os.path.join(BASE_DIR, \"weights\", f\"{EX_NO}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c48984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import Config, train\n",
    "\n",
    "config_dict = {  \n",
    "    'num_epochs': NUM_EPOCHS,   \n",
    "    'learning_rate': LEARNING_RATE,  \n",
    "    'weight_decay': WEIGHT_DECAY,  \n",
    "    'batch_size': BATCH_SIZE,  \n",
    "    'model_save_path': SAVE_PATH,  \n",
    "    'device': DEVICE\n",
    "}\n",
    "\n",
    "config = Config(**config_dict)\n",
    "history = train(train_dataset, val_dataset, model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c8c003",
   "metadata": {},
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plot import plot_training_metrics\n",
    "plot_training_metrics(history, ex=EX_NO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdaf46e3",
   "metadata": {},
   "source": [
    "**Load Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(os.path.join(BASE_DIR, \"weights\", f\"{EX_NO}.pth\"), weights_only=False)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Put Model in Evaluation mode\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3956ddcf",
   "metadata": {},
   "source": [
    "**Evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b31c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import evaluate_model\n",
    "\n",
    "evaluate_model(model, train_dataset, DEVICE, \"Train\")\n",
    "evaluate_model(model, val_dataset, DEVICE, \"Validation\")\n",
    "evaluate_model(model, test_dataset, DEVICE, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425538c",
   "metadata": {},
   "source": [
    "**Extended Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, numpy as np, torch, torch.nn.functional as F\n",
    "from typing import Dict, List, Tuple\n",
    "import models.smp_metrics as sm\n",
    "from skimage import measure\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def get_dataloaders(test_dataset):\n",
    "    return DataLoader(test_dataset, shuffle=False, batch_size=32)\n",
    "\n",
    "def get_debug(d):\n",
    "    batch = next(iter(d))\n",
    "    x1, x2, y = batch\n",
    "    print(f\"Shape of x1: {x1.shape}, Type: {type(x1)}, Dtype: {x1.dtype}\")\n",
    "    print(f\"Shape of x2: {x2.shape}, Type: {type(x2)}, Dtype: {x2.dtype}\")\n",
    "    print(f\"Shape of y: {y.shape}, Type of y: {type(y)}, Dtype: {y.dtype}, y classes: {y.unique()}\")\n",
    "    print()\n",
    "\n",
    "def prep_batch(x1, x2, y, device):\n",
    "    if not torch.is_floating_point(x1):\n",
    "        x1 = x1.float()\n",
    "    if not torch.is_floating_point(x2):\n",
    "        x2 = x2.float()\n",
    "    if torch.is_floating_point(y):\n",
    "        y = y.round().long()\n",
    "\n",
    "    x1 = x1.to(device, non_blocking=True)\n",
    "    x2 = x2.to(device, non_blocking=True)\n",
    "    y = y.to(device, non_blocking=True)\n",
    "    if y.dim() == 3:\n",
    "        y = y.unsqueeze(1)\n",
    "    return x1, x2, y\n",
    "\n",
    "def _binarize(prob_map: np.ndarray, thr: float) -> np.ndarray:\n",
    "    return (prob_map >= thr).astype(np.uint8)\n",
    "\n",
    "def _remove_small(mask: np.ndarray, min_area: int) -> np.ndarray:\n",
    "    if min_area <= 1: \n",
    "        return mask\n",
    "    lab = measure.label(mask, connectivity=1)\n",
    "    out = np.zeros_like(mask, dtype=np.uint8)\n",
    "    for r in measure.regionprops(lab):\n",
    "        if r.area >= min_area:\n",
    "            out[lab == r.label] = 1\n",
    "    return out\n",
    "\n",
    "def mask_to_instances(mask_bin: np.ndarray, min_area: int = 20) -> List[np.ndarray]:\n",
    "    mask_bin = _remove_small(mask_bin, min_area)\n",
    "    lab = measure.label(mask_bin, connectivity=1)\n",
    "    insts = []\n",
    "    for lab_id in range(1, lab.max()+1):\n",
    "        inst = (lab == lab_id).astype(np.uint8)\n",
    "        if inst.sum() > 0:\n",
    "            insts.append(inst)\n",
    "    return insts\n",
    "\n",
    "def mask_iou(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    inter = (a & b).sum()\n",
    "    if inter == 0: \n",
    "        return 0.0\n",
    "    union = a.sum() + b.sum() - inter\n",
    "    return float(inter) / float(union + 1e-6)\n",
    "\n",
    "def greedy_match_ious(preds: List[np.ndarray], gts: List[np.ndarray], iou_thr=0.5):\n",
    "    matches = []\n",
    "    U_p = set(range(len(preds)))\n",
    "    U_g = set(range(len(gts)))\n",
    "    # precompute IoU matrix\n",
    "    iou_mat = np.zeros((len(preds), len(gts)), dtype=np.float32)\n",
    "    for i, pm in enumerate(preds):\n",
    "        for j, gm in enumerate(gts):\n",
    "            iou_mat[i, j] = mask_iou(pm, gm)\n",
    "    while True:\n",
    "        best = (iou_thr, -1, -1)  # (val, i, j)\n",
    "        for i in U_p:\n",
    "            row = iou_mat[i]\n",
    "            for j in U_g:\n",
    "                val = row[j]\n",
    "                if val > best[0]:\n",
    "                    best = (val, i, j)\n",
    "        if best[1] == -1:\n",
    "            break\n",
    "        _, i, j = best\n",
    "        matches.append((i, j))\n",
    "        U_p.remove(i); U_g.remove(j)\n",
    "    return matches\n",
    "\n",
    "def instance_scores(prob_map: np.ndarray, insts: List[np.ndarray]) -> List[float]:\n",
    "    return [float(prob_map[m.astype(bool)].mean()) if m.sum() else 0.0 for m in insts]\n",
    "\n",
    "def average_precision_at_iou(pred_instances, pred_scores, gt_instances, iou_thr=0.5) -> float:\n",
    "    if len(pred_instances) == 0:\n",
    "        return 0.0\n",
    "    order = np.argsort(-np.array(pred_scores))\n",
    "    pred_instances = [pred_instances[i] for i in order]\n",
    "    pred_scores    = [pred_scores[i]    for i in order]\n",
    "\n",
    "    matched_gts = set()\n",
    "    tps, fps = [], []\n",
    "    for pm in pred_instances:\n",
    "        best_iou, best_j = 0.0, -1\n",
    "        for j, gm in enumerate(gt_instances):\n",
    "            if j in matched_gts: \n",
    "                continue\n",
    "            iou = mask_iou(pm, gm)\n",
    "            if iou > best_iou:\n",
    "                best_iou, best_j = iou, j\n",
    "        if best_iou >= iou_thr and best_j != -1:\n",
    "            tps.append(1); fps.append(0); matched_gts.add(best_j)\n",
    "        else:\n",
    "            tps.append(0); fps.append(1)\n",
    "\n",
    "    tps, fps = np.array(tps), np.array(fps)\n",
    "    cum_tp, cum_fp = np.cumsum(tps), np.cumsum(fps)\n",
    "    recalls = cum_tp / (len(gt_instances) + 1e-6)\n",
    "    precisions = cum_tp / (cum_tp + cum_fp + 1e-6)\n",
    "    # 11-point VOC\n",
    "    ap = 0.0\n",
    "    for r in np.linspace(0,1,11):\n",
    "        p_r = precisions[recalls >= r].max() if np.any(recalls >= r) else 0.0\n",
    "        ap += p_r / 11.0\n",
    "    return float(ap)\n",
    "\n",
    "# ---- image-level curves (AUROC/AUPRC) ----\n",
    "def _pr_curve(scores: np.ndarray, labels: np.ndarray):\n",
    "    order = np.argsort(-scores)\n",
    "    scores = scores[order]; labels = labels[order]\n",
    "    tp = 0; fp = 0; P = labels.sum(); N = len(labels) - P + 1e-6\n",
    "    precisions, recalls, thresholds = [], [], []\n",
    "    last = None\n",
    "    for s, y in zip(scores, labels):\n",
    "        if last is None or s != last:\n",
    "            precisions.append(tp / (tp + fp + 1e-6))\n",
    "            recalls.append(tp / (P + 1e-6))\n",
    "            thresholds.append(s)\n",
    "            last = s\n",
    "        if y == 1: tp += 1\n",
    "        else: fp += 1\n",
    "    precisions.append(tp / (tp + fp + 1e-6))\n",
    "    recalls.append(tp / (P + 1e-6))\n",
    "    thresholds.append(0.0)\n",
    "    return np.array(precisions), np.array(recalls), np.array(thresholds)\n",
    "\n",
    "def _auprc(prec, rec):\n",
    "    order = np.argsort(rec)\n",
    "    rec = rec[order]; prec = prec[order]\n",
    "    return float(np.trapz(prec, rec))\n",
    "\n",
    "def _roc_curve(scores: np.ndarray, labels: np.ndarray):\n",
    "    order = np.argsort(-scores)\n",
    "    scores = scores[order]; labels = labels[order]\n",
    "    tp=0; fp=0; P=labels.sum(); N=len(labels)-P+1e-6\n",
    "    TPR=[0.0]; FPR=[0.0]; last=None\n",
    "    for s,y in zip(scores,labels):\n",
    "        if y==1: tp+=1\n",
    "        else: fp+=1\n",
    "        if last is None or s!=last:\n",
    "            TPR.append(tp/(P+1e-6)); FPR.append(fp/(N))\n",
    "            last=s\n",
    "    TPR.append(1.0); FPR.append(1.0)\n",
    "    return np.array(FPR), np.array(TPR)\n",
    "\n",
    "def _auroc(fpr,tpr):\n",
    "    order = np.argsort(fpr)\n",
    "    return float(np.trapz(tpr[order], fpr[order]))\n",
    "\n",
    "def eval_seg(model, dataset, device, threshold=0.5) -> Dict[str, float]:\n",
    "    \"\"\"Pixel-level segmentation metrics.\"\"\"\n",
    "    loader = get_dataloaders(dataset)\n",
    "    get_debug(loader)\n",
    "\n",
    "    tot_acc=tot_rec=tot_f1=tot_iou=tot_prec=0.0\n",
    "    batches=0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x1,x2,y in loader:\n",
    "            x1,x2,y = prep_batch(x1,x2,y,device)\n",
    "            out = model(x1,x2)\n",
    "            y_main = out[0] if isinstance(out,(tuple,list)) else out\n",
    "            tp, fp, fn, tn = sm.get_statistics(y_main, y, mode='binary', threshold=threshold)\n",
    "            acc = sm.acc(tp, fp, fn, tn)\n",
    "            rec = sm.recall(tp, fp, fn, tn)\n",
    "            f1  = sm.f1(tp, fp, fn, tn)  # Dice for binary = F1\n",
    "            iou = sm.iou(tp, fp, fn, tn)\n",
    "            prec= sm.prec(tp, fp, fn, tn)\n",
    "            tot_acc += acc; tot_rec += rec; tot_f1 += f1; tot_iou += iou; tot_prec += prec; batches+=1\n",
    "\n",
    "    return {\n",
    "        \"task\":\"segmentation(pixel)\",\n",
    "        \"accuracy\": float(tot_acc/batches),\n",
    "        \"recall\":   float(tot_rec/batches),\n",
    "        \"precision\":float(tot_prec/batches),\n",
    "        \"f1(dice)\": float(tot_f1/batches),\n",
    "        \"iou\":      float(tot_iou/batches),\n",
    "        \"batches\":  int(batches)\n",
    "    }\n",
    "\n",
    "def eval_det(model, dataset, device, iou_thresh=0.5, prob_thr=0.5, min_area=20) -> Dict[str, float]:\n",
    "    \"\"\"Instance-level detection from segmentation logits.\"\"\"\n",
    "    loader = get_dataloaders(dataset)\n",
    "    get_debug(loader)\n",
    "\n",
    "    total_matches=total_pred=total_gt=0\n",
    "    ap_list=[]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x1,x2,y in loader:\n",
    "            x1,x2,y = prep_batch(x1,x2,y,device)\n",
    "            out = model(x1,x2)\n",
    "            y_main = out[0] if isinstance(out,(tuple,list)) else out\n",
    "            if y_main.shape[-2:] != y.shape[-2:]:\n",
    "                y_main = F.interpolate(y_main, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
    "            prob = torch.sigmoid(y_main).detach().cpu().numpy()\n",
    "            gt   = y.detach().cpu().numpy().astype(np.uint8)\n",
    "            B = prob.shape[0]\n",
    "            for b in range(B):\n",
    "                p = prob[b,0]; g = gt[b,0]\n",
    "                pred_bin = _binarize(p, prob_thr)\n",
    "                pred_inst = mask_to_instances(pred_bin, min_area=min_area)\n",
    "                gt_inst   = mask_to_instances(g,        min_area=min_area)\n",
    "                scores    = instance_scores(p, pred_inst)\n",
    "                matches   = greedy_match_ious(pred_inst, gt_inst, iou_thr=iou_thresh)\n",
    "\n",
    "                total_matches += len(matches)\n",
    "                total_pred    += len(pred_inst)\n",
    "                total_gt      += len(gt_inst)\n",
    "                ap_list.append(average_precision_at_iou(pred_inst, scores, gt_inst, iou_thr=iou_thresh))\n",
    "\n",
    "    tp = total_matches\n",
    "    fp = total_pred - tp\n",
    "    fn = total_gt - tp\n",
    "    precision = tp / (tp + fp + 1e-6)\n",
    "    recall    = tp / (tp + fn + 1e-6)\n",
    "    f1        = 2*precision*recall/(precision+recall+1e-6)\n",
    "    ap_mean   = float(np.mean(ap_list) if ap_list else 0.0)\n",
    "    return {\n",
    "        \"task\":\"detection(instance)\",\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\":    float(recall),\n",
    "        \"f1\":        float(f1),\n",
    "        f\"AP@{iou_thresh:.2f}\": ap_mean,\n",
    "        \"TP\": int(tp), \"FP\": int(fp), \"FN\": int(fn),\n",
    "        \"num_images\": int(total_pred + fn)  # approximate count traversed\n",
    "    }\n",
    "\n",
    "def eval_image(model, dataset, device, prob_thr_for_instances=0.5, min_area=20) -> Dict[str, float]:\n",
    "    \"\"\"Image-level presence metrics (AUROC/AUPRC) robust to imbalance.\"\"\"\n",
    "    loader = get_dataloaders(dataset)\n",
    "    model.eval()\n",
    "    img_scores=[]; img_labels=[]\n",
    "    with torch.no_grad():\n",
    "        for x1,x2,y in loader:\n",
    "            x1,x2,y = prep_batch(x1,x2,y,device)\n",
    "            out = model(x1,x2)\n",
    "            y_main = out[0] if isinstance(out,(tuple,list)) else out\n",
    "            if y_main.shape[-2:] != y.shape[-2:]:\n",
    "                y_main = F.interpolate(y_main, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
    "            prob = torch.sigmoid(y_main).detach().cpu().numpy()\n",
    "            gt   = y.detach().cpu().numpy().astype(np.uint8)\n",
    "            B = prob.shape[0]\n",
    "            for b in range(B):\n",
    "                p = prob[b,0]; g = gt[b,0]\n",
    "                y_img = 1 if g.sum() > 0 else 0\n",
    "                pred_bin = (p >= prob_thr_for_instances).astype(np.uint8)\n",
    "                insts = mask_to_instances(pred_bin, min_area=min_area)\n",
    "                score = float(np.max(instance_scores(p, insts))) if len(insts)>0 else 0.0\n",
    "                img_scores.append(score); img_labels.append(y_img)\n",
    "\n",
    "    scores = np.asarray(img_scores, dtype=np.float32)\n",
    "    labels = np.asarray(img_labels, dtype=np.int32)\n",
    "    # PR & ROC\n",
    "    prec, rec, thr = _pr_curve(scores, labels)\n",
    "    auprc = _auprc(prec, rec)\n",
    "    fpr, tpr = _roc_curve(scores, labels)\n",
    "    auroc = _auroc(fpr, tpr)\n",
    "    # F1-optimal threshold (optional calibration)\n",
    "    f1s = 2*prec*rec/(prec+rec+1e-6)\n",
    "    best_idx = int(np.nanargmax(f1s))\n",
    "    return {\n",
    "        \"task\":\"image-level(presence)\",\n",
    "        \"AUROC\": float(auroc),\n",
    "        \"AUPRC\": float(auprc),\n",
    "        \"best_F1\": float(f1s[best_idx]),\n",
    "        \"best_threshold\": float(thr[best_idx]),\n",
    "        \"positives\": int(labels.sum()),\n",
    "        \"negatives\": int((1-labels).sum()),\n",
    "        \"num_images\": int(len(labels))\n",
    "    }\n",
    "\n",
    "def evaluate(model, dataset, device, task=\"seg\", **kwargs) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Dispatch to the correct evaluator.\n",
    "    task: \"seg\" | \"det\" | \"image\"\n",
    "    kwargs forwarded to the specific evaluator.\n",
    "    \"\"\"\n",
    "    if task == \"seg\":\n",
    "        return eval_seg(model, dataset, device, **kwargs)\n",
    "    elif task == \"det\":\n",
    "        return eval_det(model, dataset, device, **kwargs)\n",
    "    elif task == \"image\":\n",
    "        return eval_image(model, dataset, device, **kwargs)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown task: {task}\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import Dict, List\n",
    "import models.smp_metrics as sm\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_pixel_metrics(model, dataset, device, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      per_image: dict of lists (iou, dice, precision, recall, accuracy)\n",
    "      totals: dict with aggregated TP/FP/FN/TN over all pixels\n",
    "    \"\"\"\n",
    "    loader = get_dataloaders(dataset)\n",
    "    get_debug(loader)\n",
    "\n",
    "    per_iou, per_dice, per_prec, per_rec, per_acc = [], [], [], [], []\n",
    "\n",
    "    tot_tp = tot_fp = tot_fn = tot_tn = 0\n",
    "    model.eval()\n",
    "    for x1, x2, y in loader:\n",
    "        x1, x2, y = prep_batch(x1, x2, y, device)\n",
    "        out = model(x1, x2)\n",
    "        y_main = out[0] if isinstance(out, (tuple, list)) else out\n",
    "        if y_main.shape[-2:] != y.shape[-2:]:\n",
    "            y_main = F.interpolate(y_main, size=y.shape[-2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        # batch pixel metrics\n",
    "        tp, fp, fn, tn = sm.get_statistics(y_main, y, mode='binary', threshold=threshold)\n",
    "\n",
    "        # reduce to scalars\n",
    "        acc = sm.acc(tp, fp, fn, tn)\n",
    "        rec = sm.recall(tp, fp, fn, tn)\n",
    "        f1  = sm.f1(tp, fp, fn, tn)        # Dice == F1 in binary segmentation\n",
    "        iou = sm.iou(tp, fp, fn, tn)\n",
    "        prec= sm.prec(tp, fp, fn, tn)\n",
    "\n",
    "        # get per-image by splitting batch accumulators image-wise\n",
    "        # sm.* functions usually support tensor inputs; to get per-image,\n",
    "        # we recompute with thresholded preds per sample quickly:\n",
    "        probs = torch.sigmoid(y_main)\n",
    "        preds = (probs >= threshold).long()\n",
    "        B = y.shape[0]\n",
    "        for b in range(B):\n",
    "            tp_b, fp_b, fn_b, tn_b = sm.get_stats_simple(preds[b:b+1], y[b:b+1]) if hasattr(sm, \"get_stats_simple\") else sm.get_statistics(preds[b:b+1].float(), y[b:b+1], mode='binary', threshold=0.5)\n",
    "            acc_b = sm.acc(tp_b, fp_b, fn_b, tn_b)\n",
    "            rec_b = sm.recall(tp_b, fp_b, fn_b, tn_b)\n",
    "            f1_b  = sm.f1(tp_b, fp_b, fn_b, tn_b)\n",
    "            iou_b = sm.iou(tp_b, fp_b, fn_b, tn_b)\n",
    "            prec_b= sm.prec(tp_b, fp_b, fn_b, tn_b)\n",
    "            per_acc.append(float(acc_b)); per_rec.append(float(rec_b))\n",
    "            per_dice.append(float(f1_b)); per_iou.append(float(iou_b)); per_prec.append(float(prec_b))\n",
    "\n",
    "        # accumulate totals\n",
    "        tot_tp += int(tp.sum().item()); tot_fp += int(fp.sum().item())\n",
    "        tot_fn += int(fn.sum().item()); tot_tn += int(tn.sum().item())\n",
    "\n",
    "    per_image = dict(iou=per_iou, dice=per_dice, precision=per_prec, recall=per_rec, accuracy=per_acc)\n",
    "    totals = dict(TP=tot_tp, FP=tot_fp, FN=tot_fn, TN=tot_tn)\n",
    "    return per_image, totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5311471",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# SEGMENTATION (pixel-level)\n",
    "seg_metrics = evaluate(model, test_dataset, device, task=\"seg\", threshold=0.5)\n",
    "print(seg_metrics)\n",
    "# IMAGE-LEVEL PRESENCE\n",
    "img_metrics = evaluate(model, test_dataset, device, task=\"image\", prob_thr_for_instances=0.5, min_area=20)\n",
    "print(img_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyenv)",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
