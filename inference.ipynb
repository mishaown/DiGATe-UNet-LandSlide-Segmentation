{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3efb13d7",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "- **Dataset:** Bijie Dataset\n",
    "- **Backbone:** EfficientNet B4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915b66af",
   "metadata": {},
   "source": [
    "**Prepare the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 1941\n",
      "Number of validation samples: 554\n",
      "Number of test samples: 278\n",
      "<class 'torch.Tensor'> torch.Size([3, 256, 256]) -0.14067722856998444 1.0951991081237793\n",
      "<class 'torch.Tensor'> torch.Size([3, 256, 256]) -0.14775483310222626 1.1545225381851196\n",
      "<class 'torch.Tensor'> torch.Size([256, 256]) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import torch\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "\n",
    "from dataset import BijieRawDataset, TwoComposites, DualStreamTransform\n",
    "\n",
    "EX_NO = 'ef_b4'\n",
    "# Data directory\n",
    "DATA_DIR = \"/home/user1/ms/Datasets/Bijie-landslide-dataset\"\n",
    "# Base directory\n",
    "BASE_DIR = \"/home/user1/ms/DiGATe-UNet-LandSlide-Segmentation\" \n",
    "\n",
    "landslide_ds = BijieRawDataset(f\"{DATA_DIR}/landslide\", phase=\"landslide\")\n",
    "nonlandslide_ds = BijieRawDataset(f\"{DATA_DIR}/non-landslide\", phase=\"non-landslide\")\n",
    "\n",
    "# Set a fixed seed for reproducibility\n",
    "seed = 42\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# split each one into train/val/test using the generator\n",
    "def split(ds, ratios=(.7,.2,.1), generator=None):\n",
    "    n = len(ds)\n",
    "    sizes = [int(r * n) for r in ratios]\n",
    "    sizes[2] = n - sum(sizes[:2])\n",
    "    return random_split(ds, sizes, generator=generator)\n",
    "\n",
    "# Apply the split with reproducible shuffling\n",
    "tl, vl, sl = split(landslide_ds, generator=generator)\n",
    "tn, vn, sn = split(nonlandslide_ds, generator=generator)\n",
    "\n",
    "# concat landslide + non‐landslide for each split\n",
    "train_ds = ConcatDataset([tl, tn])\n",
    "val_ds   = ConcatDataset([vl, vn])\n",
    "test_ds  = ConcatDataset([sl, sn])\n",
    "\n",
    "train_dataset = TwoComposites(train_ds, bands='RGB&DEM', resize_to=256, transform=DualStreamTransform())\n",
    "val_dataset = TwoComposites(val_ds, bands='RGB&DEM', resize_to=256, transform=None)\n",
    "test_dataset = TwoComposites(test_ds, bands='RGB&DEM', resize_to=256, transform=None)\n",
    "\n",
    "image1, image2, mask = train_dataset[0]\n",
    "\n",
    "print(f\"Number of training samples: {len(train_ds)}\")\n",
    "print(f\"Number of validation samples: {len(val_ds)}\")\n",
    "print(f\"Number of test samples: {len(test_ds)}\")\n",
    "\n",
    "print(type(image1), image1.shape, image1.min().item(), image1.max().item())\n",
    "print(type(image2), image2.shape, image2.min().item(), image2.max().item())\n",
    "print(type(mask), mask.shape, mask.min().item(), mask.max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592fdda",
   "metadata": {},
   "source": [
    "**Load the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3a822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/.conda/envs/pyenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n",
      "Unexpected keys (bn2.bias, bn2.num_batches_tracked, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from models import DiGATe_Unet\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using device: {DEVICE}')\n",
    "\n",
    "model = DiGATe_Unet(\n",
    "        n_classes=1,\n",
    "        backbone=\"tf_efficientnet_b4\",\n",
    "        n_channels=3,\n",
    "        pretrained=True,         \n",
    "        pretrained_path=None,     \n",
    "        use_input_adapter=False,\n",
    "        freeze_backbone=True,\n",
    "        share_backbone=False\n",
    "    ).to(DEVICE)\n",
    "\n",
    "checkpoint = torch.load(os.path.join(BASE_DIR, \"weights\", f\"{EX_NO}.pth\"), weights_only=False)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959f3cb8",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d2a68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 18/18 [00:07<00:00,  2.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Metrics on Validation Set---\n",
      "Acc       : 0.9892\n",
      "Recall    : 0.9295\n",
      "Prec      : 0.9434\n",
      "F1        : 0.9102\n",
      "Iou       : 0.8826\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:03<00:00,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation Metrics on Test Set---\n",
      "Acc       : 0.9897\n",
      "Recall    : 0.9249\n",
      "Prec      : 0.9453\n",
      "F1        : 0.9111\n",
      "Iou       : 0.8840\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate import evaluate_model\n",
    "\n",
    "evaluate_model(model, val_dataset, DEVICE, \"Validation\")\n",
    "evaluate_model(model, test_dataset, DEVICE, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca43d7",
   "metadata": {},
   "source": [
    "**Save Predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27de3118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def save_all_predictions_with_heatmap(model, dataset, device, ex_no, alpha=0.45):\n",
    "    \n",
    "    output_dir = f'visuals/{ex_no}/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    model.to(device).eval()\n",
    "\n",
    "    for idx in tqdm(range(len(dataset)), desc=\"Inference\"):\n",
    "        x1, x2, y_true = dataset[idx]\n",
    "        x1_dev = x1.unsqueeze(0).to(device)\n",
    "        x2_dev = x2.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = model(x1_dev, x2_dev)\n",
    "            y_main = out[0] if isinstance(out, (tuple, list)) else out  # (B,1,H,W) logits\n",
    "            prob = torch.sigmoid(y_main)                                # (B,1,H,W) in [0,1]\n",
    "            y_pred = (prob > 0.5).float()\n",
    "\n",
    "        img = x1[:3].permute(1, 2, 0).cpu().numpy()\n",
    "        # Normalize to 0..1 if outside\n",
    "        if img.max() > 1.0 or img.min() < 0.0:\n",
    "            img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "\n",
    "        true_mask = y_true.squeeze().cpu().numpy()\n",
    "        pred_mask = y_pred.squeeze().cpu().numpy()\n",
    "        heat = prob.squeeze().cpu().numpy()  # smooth heatmap in [0,1]\n",
    "\n",
    "        # Plot and save: Image | Ground Truth | Prediction | Image+Heatmap\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "        # Original RGB\n",
    "        axes[0].imshow(img)\n",
    "        axes[0].set_title(\"Image\")\n",
    "        axes[0].axis(\"off\")\n",
    "\n",
    "        # Ground Truth\n",
    "        axes[1].imshow(true_mask, cmap=\"gray\")\n",
    "        axes[1].set_title(\"Ground Truth\")\n",
    "        axes[1].axis(\"off\")\n",
    "\n",
    "        # Prediction (binary)\n",
    "        axes[2].imshow(pred_mask, cmap=\"gray\", vmin=0, vmax=1)\n",
    "        axes[2].set_title(\"Prediction\")\n",
    "        axes[2].axis(\"off\")\n",
    "\n",
    "        # Image + Heatmap overlay (blue=0, red=1)\n",
    "        axes[3].imshow(img)\n",
    "        hm = axes[3].imshow(heat, cmap=\"bwr\", vmin=0.0, vmax=1.0, alpha=alpha)\n",
    "        axes[3].set_title(\"Image + Heatmap\")\n",
    "        axes[3].axis(\"off\")\n",
    "\n",
    "        cbar = fig.colorbar(hm, ax=axes[3], fraction=0.046, pad=0.04)\n",
    "        cbar.set_label(\"Predicted probability\", rotation=270, labelpad=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        save_path = os.path.join(output_dir, f\"sample_{idx}.png\")\n",
    "        plt.savefig(save_path, dpi=200, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    print(f\"✅ Saved all predictions (with heatmaps) to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f276c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# save_all_predictions_with_heatmap(model, test_dataset, device, ex_no=EX_NO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyenv)",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
